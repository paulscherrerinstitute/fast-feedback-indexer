\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
%\usepackage{dsfont}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{algorithm}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{listings}

\usepackage[backend=bibtex,style=numeric]{biblatex}
\addbibresource{bibliography}

\DeclareMathOperator*{\mirror}{\longrightarrow}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator{\trimop}{trim}
\DeclareMathOperator{\trace}{trace}
\DeclareMathOperator{\similar}{similarity}
\DeclareMathOperator{\acos}{acos}

\newcommand{\vect}[1]{\mathbf{#1}}
\newcommand{\mat}[1]{\mathbf{#1}}
\newcommand{\round}[1]{\lfloor #1 \rceil}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\ceil}[1]{\lceil #1 \rceil}
\newcommand{\distZ}[1]{d_\mathbb{Z}(#1)}
\newcommand{\diffZ}[1]{\Delta_\mathbb{Z}(#1)}
\newcommand{\distvecZ}[1]{\vect{d}_\mathbb{Z}(#1)}
\newcommand{\diffvecZ}[1]{\vect{\Delta}_\mathbb{Z}(#1)}
\newcommand{\trim}[3]{\trimop_{#1}^{#2}\left ( #3 \right )}
\newcommand{\filter}[1]{F^{#1}}

%opening
\title{Fast Feedback Indexer}
\author{Hans-Christian Stadler Kleeb\thanks{hans-christian.stadler@psi.ch}}

\begin{document}

\maketitle

\begin{abstract}
This article gives a description of the API for the fast feedback indexing algorithm (FFBI) implemented in this repository.
\end{abstract}

\section{Intro}\label{sec:intro}

The fast feedback indexer (FFBI) is implemented in C++17 with CUDA \cite{cuda} underneath. Additionally there are primitive wrappers for Python3 and C98.

One part of the API, called the \emph{raw} API, only depends on the standard C++ library. With the \emph{raw} API, it is possible to call the GPU part of FFBI. This part delivers unit cell candidates with associated scores.

Another part additionally depends on the \emph{Eigen} library \cite{eigenweb}. The most important part is the refinement of cell candidates obtained from the \emph{raw} API and selecting final results. This part also provides a \emph{convenience} API, wrapping the \emph{raw} API in a less performant, but more convenient object oriented interface. This API, although cell refinement and result selection do not strictly belong to that part, will be called \emph{convenience} API in its entirety.

Both \emph{raw} and \emph{convenience} API provide means to call the GPU code asynchronously.

The Python3 and C98 wrappers are currently less performant APIs for experimental convenience.

\section{\emph{Raw} API}
\lstset{language=C++}

This API is accessible through the header file ``ffbidx/indexer.h'' under the namespace \emph{fast\_feed\-back}. The \emph{raw} API centers around an \emph{indexer} object with a persistent state on the host and the GPU. This object, once created using the \emph{persistent} configuration parameters, is used to call the GPU part of the indexing operation with parameters given as a \emph{runtime} configuration and \emph{input} and \emph{output} parameters.
%
\begin{lstlisting}
template <typename float_type=float>
struct indexer {
    config_persistent<float_type> cpers;
    const state_id::type state;

    static void init (indexer<float_type>& instance,
        const config_persistent<float_type>& conf);
    static void drop (indexer<float_type>& instance);

    indexer ();
    indexer (const config_persistent<float_type>& c);
    indexer (const indexer& other);
    indexer& operator= (const indexer& other);
    indexer (indexer&& other);
    indexer& operator= (indexer&& other);
    ~indexer ();

    void index_start (const input<float_type>& in,
        output<float_type>& out,
        const config_runtime<float_type>& conf_rt,
        void(*callback)(void*)=nullptr,
        void* data=nullptr);
    void index_end (output<float_type>& out);
    void index (const input<float_type>& in,
        output<float_type>& out,
        const config_runtime<float_type>& conf_rt)
};
\end{lstlisting}
%
The indexer object is templated on the floating point type. Currently, only \emph{float} is supported, leaving the possibility to support \emph{double}, or a \emph{half} precision floating point type open for the future.

When creating an indexer object, state is allocated on the host and on the GPU. This is expensive, so the default constructor should \textbf{NOT} be called, unless you are sure the default \emph{persistent} configuration is appropriate, or there is no way to get around the call. The copying versions of the constructor and assignment operator first drop the existing state, then allocate a new state on the GPU.

The \textbf{index\_start} method copies input data to the GPU and launches the GPU kernels with parameters given in the \emph{runtime} configuration, and the \emph{input} and \emph{output} parameters. The \emph{output} data must not be tampered with until \emph{index\_end} has been called. If the \emph{callback} function is given, it will be called with the \emph{data} parameter asynchronously after output data is ready in GPU memory. The \emph{callback} function is not allowed to call CUDA code, including the \emph{index\_end} method.

The \textbf{index\_end} method will copy output data from GPU memory to host memory. If the \emph{callback} function was provided when calling \emph{index\_start}, this function will assume the data is ready. Otherwise it will do the necessary synchronization and wait for the data to be ready.

The \textbf{index} method is a convenience wrapper that just calls the other two index\_x methods.

\subsection{\emph{Persistent} Configuration}

The \emph{persistent} configuration contains information about the size and nature of the persistent state allocation that belong to an \emph{indexer} object.
%
\begin{lstlisting}
template <typename float_type=float>
struct config_persistent {
    unsigned max_output_cells=1;
    unsigned max_input_cells=1;
    unsigned max_spots=200;
    unsigned num_candidate_vectors=32;
    bool redundant_computations=false;
};
\end{lstlisting}
%
The \textbf{max\_output\_cells} member limits the number of memory allocated for candidate unit cell orientations in the output, and is called $Q$ in the algorithm description. The same applies to the input unit cells with the \emph{max\_input\_cells} member. If more input cells are given with the \emph{input} parameter, only the first of these cells are copied to the GPU.

The \textbf{max\_spots} member limits the number of spots copied to GPU memory. If more spots are given with the \emph{input} parameter, only the first of these spots are copied to the GPU.

The \textbf{num\_candidate\_vectors} gives the number of candidate unit cell vector orientations to proceed with after the first vector orientation sampling stage. This parameter is called $P$ in the algorithm description.

If the \textbf{redundant\_computations} member is set to \emph{false}, only the longest vectors of each input cell are used in the vector orientation sampling stage. If set to \emph{true}, vector sampling is carried out for all three vectors of each input unit cell. If the spot pattern is well behaved and sampling is fine enough, this will not be necessary, as the same solution will be found for every vector of an input cell. For ill-behaved spot patterns or coarse grained sampling, considering all input cell vectors might not be redundant, but helps to find better solutions and increase robustness.

\subsection{\emph{Runtime} Configuration}

The \emph{runtime} configuration contains parameters for the various algorithmic parts involved in calculating the output cells. When serving as a parameter for indexing, this structure must be in \emph{pinned} memory.
%
\begin{lstlisting}
// This structure must be in pinned memory
// when serving as a parameter for indexing
template <typename float_type=float>
struct config_runtime {
    float_type length_threshold=1e-9;
    float_type triml=0.001;
    float_type trimh=0.3;
    float_type delta=0.1;
    float_type dist1=0.3;
    float_type dist3=0.2;
    unsigned num_halfsphere_points=32*1024;
    unsigned num_angle_points=0;
};
\end{lstlisting}
%
The \textbf{length\_threshold} member, called $t_l$ in the following, is used to determine if two vectors have the same length. This is deemed to be true if
%
\[
\|\vect{v}_1\| \in \left [\:\|\vect{v}_2\|(1-t_l)\ \hdots\ \|\vect{v}_2\|(1+t_l)\: \right ]
\]
%
Vectors of same length are forming a candidate group. Sampling is performed just once based on a vector with representative length for the entire group. This representing vector is taken as the first vector in the first cell.

The \textbf{triml}, \textbf{trimh}, and \textbf{delta} members are used for candidate unit cell vector and unit cell orientation subscoring. They are called $l$, $h$, and $\delta$ in the algorithm description.

The \textbf{dist1} and \textbf{dist3} members are used for candidate unit cell vector and unit cell orientation scoring, respectively. They are subsumed in the $\beta$ parameter in the algorithm description.

The \textbf{num\_halfsphere\_points} member is the number of sampling points used for the candidate unit cell vector orientation sampling. This parameter is called $P^*$ in the algorithm description.

The \textbf{num\_angle\_points} member is the number of rotation angle sampling points used for candidate unit cell orientation sampling. This parameter is called $Q^*$ in the algorithm description. If this member is set to $0$, it will be set automatically to $2.5\,\sqrt{P^*}$ to approximately maintain the sampling density.

\subsection{Input}

The \emph{input} data gives the input cell vectors and spot vectors by consecutive $\vect{x},\vect{y},\vect{z}$ coordinate vectors in \textbf{pinned} memory. Memory pinning is explained in a later section. The $i$th vector ($i$ zero based) of the $j$th input cell ($j$ zero based) must be given as $[\vect{x}_{3j+i}\ \vect{y}_{3j+i}\ \vect{z}_{3j+i}]$. The $i$th spot must be given as $[\vect{x}_i\ \vect{y}_i\ \vect{z}_i]$.
%
\begin{lstlisting}
template <typename float_type=float>
struct input {
    struct {
        float_type* x;  // pinned memory
        float_type* y;  // pinned memory
        float_type* z;  // pinned memory
    } cell;
    struct {
        float_type* x;  // pinned memory
        float_type* y;  // pinned memory
        float_type* z;  // pinned memory
    } spot;
    unsigned n_cells;
    unsigned n_spots;
    bool new_cells;
    bool new_spots;
};
\end{lstlisting}
%
The \textbf{n\_cells} member gives the number of input cells. The size of the input cell coordinate vectors must be $3$ times as big and give the real space unit cell vector coordinates.

The \textbf{n\_spots} member gives the number of spots. The size of the spot coordinate vectors must be of this size and give the reciprocal space spot coordinates.

The \textbf{new\_cells} member needs to be \emph{true} if the input cell data is to be copied into GPU memory. If the existing input cell data in GPU memory is up to date, it can be set to \emph{false}, preventing unnecessary data copying to GPU memory.

The \textbf{new\_spots} member needs to be set to \emph{true} if the spot data is to be copied into GPU memory. If the existing spot data in GPU memory is up to date, it can be set to \emph{false}, preventing unnecessary data copying to GPU memory.

\subsection{Output}

The \emph{output} data will receive reoriented unit cells candidates with a score. The unit cell vectors are stored as consecutive $\vect{x},\vect{y},\vect{z}$ coordinate vectors in \textbf{pinned} memory. Memory pinning is explained in a later section. The $i$th vector ($i$ zero based) of the $j$th candidate cell ($j$ zero based) is stored as $[\vect{x}_{3j+i}\ \vect{y}_{3j+i}\ \vect{z}_{3j+i}]$. And the score for the $j$th candidate cell is stored in $\vect{score}_j$.
%
\begin{lstlisting}
template <typename float_type=float>
struct output {
    float_type* x;      // pinned memory
    float_type* y;      // pinned memory
    float_type* z;      // pinned memory
    float_type* score;  // pinned memory
    unsigned n_cells=1u;
};
\end{lstlisting}
%
The \textbf{n\_cells} member gives the number of output candidate cells. The coordinate and score vectors must be preallocated to have enough space for storing as many candidate cells and scores. The \emph{n\_cells} must be smaller than \emph{max\_output\_cells} from the persistent configuration.

Compared to the algorithm description, the scores have the opposite sign. So the more negative a score, the more promising a candidate cell is.

\subsection{Memory Pinning}

For the CUDA asynchronous memory transfers used in the \emph{raw} API to move memory back and forth between host and GPU memory, memory pinning is required. This basically fixes the physical host memory adresses of the underlying memory.

There are two smart pointer like abstractions to hold pinned memory. The \textbf{memory\_pin} object is designed for pinning existing unpinned memory. The \textbf{pinned\_ptr} is a specialized standard \emph{unique\_ptr}, designed to hold pinned memory allocated with the pinned memory allocation function \textbf{alloc\_pinned}. It's possible to just mix and match different types for handling pinned memory, only the most typical usage will be described here.
%
\begin{lstlisting}
struct memory_pin {
    void* ptr;
    memory_pin() noexcept;
    memory_pin(void* mem_ptr, std::size_t num_bytes);

    template<typename Container>
    memory_pin(const Container& container);

    memory_pin(memory_pin&& other) noexcept;
    memory_pin& operator=(memory_pin&& other);
    ~memory_pin();

    template<typename Object>
    static memory_pin on(const Object& obj)

    template<typename Object>
    static memory_pin on(const Object* obj_ptr);

    static void pin(void* ptr, std::size_t size);
    static void unpin(void* ptr);
};

void* alloc_pinned(std::size_t num_bytes);
void dealloc_pinned(void* ptr);

template<typename T>
class pinned_ptr;

template<typename T>
pinned_ptr<T> alloc_pinned();
\end{lstlisting}

\subsubsection{Allocate and Deallocate Pinned Memory}

The \textbf{alloc\_pinned}(size in bytes) function allocates pinned memory and returns a void pointer to the memory. The \textbf{dealloc\_pinned} function deallocated pinned memory. If you want to manage pinned memory on your own, use this pair of functions.

The pointer to pinned memory returned by the \emph{alloc\_pinned}(size in bytes) function can be used to initialize the \textbf{pinned\_ptr} smart pointer. It will call \emph{dealloc\_pinned} automatically when going out of scope and otherwise works exactly like a standard \emph{unique\_ptr}.

The templated version of \emph{alloc\_pinned}$<$T$>$ combines pinned memory allocation of sizeof(T) bytes with the initialization of a \emph{pinned\_ptr}$<$T$>$.

The following example allocates a pinned float array and a pinned struct with cell data, providing access through \emph{pinned\_ptr} in both cases:
%
\begin{lstlisting}
pinned_ptr<float[]> spots(
    static_cast<float*>(
        alloc_pinned(3*nspots*sizeof(float))
    )
);

struct data_t { float cell[9]; };
auto data = alloc_pinned<data_t>();
\end{lstlisting}

\subsubsection{Pin Existing Data}

The \textbf{memory\_pin} object sets a pin on existing data. It's the programmers responsibility, that this data is newer moved away from the pinned area in memory. For containers this usually means not changing the content.

\subsection{Exception Handling}

The \emph{raw} API provides an exception object specialized from the standard exception object. It provides the usual methods.
%
\begin{lstlisting}
struct exception : public std::exception {
    std::string error_message;
    const char* file_name;
    unsigned line_number;
}
\end{lstlisting}
%
The \textbf{error\_message} can be retrieved by the \emph{what} method. In addition, the exception keeps the \textbf{file\_name} and \textbf{line\_number} of the source location that threw the exception.

\subsection{Thread Safety}

The \emph{raw} interface is not thread safe, in the sense that either every thread is supposed to have it's own \emph{indexer} object, or threads serialize access to such objects.

\subsection{Environment Variables}

The \emph{raw} API functions reacts to a number of environment variables:
%
\begin{itemize}
 \item \textbf{INDEXER\_LOG\_LEVEL} (string): The log level for the indexer - \emph{fatal}, \emph{error}, \emph{warn}, \emph{info}, \emph{debug}
 \item \textbf{INDEXER\_GPU\_DEVICE} (int): The GPU cuda device number to use for indexing parsed on indexer object creation. If this variable is not set, the current GPU cuda device is used.
 \item \textbf{INDEXER\_GPU\_DEBUG} (string): Print gpu kernel debug output to stdout \{1, true, yes, on, 0, false, no, off\}. Parsed on indexer object creation.
 \item \textbf{INDEXER\_VERBOSE\_EXCEPTION} (string): Add (file:line) before exception message \{1, true, yes, on, 0, false, no, off\}. Parsed on exception creation.
\end{itemize}

\subsection{Miscellaneous}

A logging API is provided for internal purposes.

\section{\emph{Convenience} API}

This API is declared in the file ``ffbidx/refine.h'' under the namespace \emph{fast\_feed\-back::re\-fine}. The \emph{convenience} API provides basic functionality for cell refinement, cell similarity, and cell selection. Then it provides object oriented convenience wrappers for the \emph{raw} API, hence the name. The \emph{convenience} API relies on data stored as vectors and matrices as defined by the Eigen library \cite{eigenweb}. Eigen matrices are stores in column major order.

\subsection{Basic Functionality}

As basic functionality, the \emph{convenience} API provides functions for cell candidate refinement, calculating the cell similarity score, and for selecting the best candidate cell, as well as several candidate cells representing different crystals.

\subsubsection{Unit Cell Candidates Refinement}

The \emph{convenience} API declares a static member function of the class \emph{ifss} (iterative fit to selected spots) to refine unit cell candidates and recalculate their scores. The method is described in the algorithm description.
%
\begin{lstlisting}
template <typename float_type=float>
struct indexer_ifss : public indexer<float_type> {
    ...
    template<typename MatX3, typename VecX>
    static void refine (
        const Ref<MatrixX3<float_type>>& spots,
        DenseBase<MatX3>& cells,
        DenseBase<VecX>& scores,
        const config_ifss<float_type>& cifss,
        unsigned block=0, unsigned nblocks=1
    );
    ...
};
\end{lstlisting}

The \textbf{spots} matrix in $\mathbb{R}^{n\times 3}$ gives the $n$ spot coordinates as row vectors in reciprocal space.

The \textbf{cells} matrix in $\mathbb{R}^{3m\times 3}$ gives the cell vectors of $m$ candidate unit cells as consecutive triplets of row vectors in real space. These unit cell candidates will be replaced with the refined candidates.

The \textbf{scores} vector in $\mathbb{R}^m$ gives the $m$ scores for the $m$ candidate unit cells. These scores are expected to be the scoring results from the \emph{raw} API for the candidate cells in the \emph{cells} matrix. Scores will be replaced with $\distZ{\prescript{min\_spots}{}{\vect{z}}}$, as defined in the algorithm description, and the \emph{min\_spots} refinement parameter is described later.

The \textbf{cifss} configuration gives the refinement parameters and is described below in Section \ref{subsub:refparams}.

The \textbf{block} and \textbf{nblocks} members are used to split the refinement task into independent pieces of work on batches of candidate cells. The $m$ cells are split into batches of at most $\ceil{\frac{m}{nblock}}$ candidate cells. The \emph{block} parameter specifies which block should be worked on, with $0\leq block < nblocks$.

\subsubsection{Refinement Parameters}\label{subsub:refparams}

\begin{lstlisting}
template <typename float_type=float>
struct config_ifss {
    float_type threshold_contraction=.8;
    float_type max_distance=.01;
    unsigned min_spots=6;
    unsigned max_iter=15;
};
\end{lstlisting}

The \textbf{threshold\_contraction} member is used to tighten the closeness threshold for every iteration in the cell orientation refinement algorithm. This parameter is called $\lambda$ in the algorithm description.

The \textbf{min\_spots} member is used as a threshold for the minimum number of close spots. This parameter is called $m$ in the refinement algorithm description.

The \textbf{max\_iter} member is used to limit the number of refinement iterations. This parameter is called $maxiter$ in the refinement algorithm description.

The \textbf{max\_distance} parameter is used as an experimental extra stop criterion for the refinement loop. It is not described in the algorithm description. To match the algorithm description, it would have to be set to $0$. Looking at the algorithm description, the loop will stop if the closeness threshold $t$ is less than \emph{max\_distance}. The value of \emph{max\_distance} should therefore be less than the parameter $\beta$ in the algorithm description.

\subsubsection{Cell Similarity}

The cell similarity function computes a similarity score for two matrices based on the vector length differences and matrix determinant differences. It can be used to modify final scores, e.g. in the sense of a penalty function.
%
\begin{lstlisting}
template <typename CellMatA,
          typename CellMatB,
          typename float_type=typename CellMatA::Scalar>
float_type cell_similarity (
    const MatrixBase<CellMatA>& cellA,
    const MatrixBase<CellMatB>& cellB,
    float_type threshold=.02f
);
\end{lstlisting}
%
The \textbf{cellA} and \textbf{cellB} matrices are to be compared for similarity. The similarity score differs in two ways from the algorithm describtion.
%
\begin{enumerate}
 \item The \textbf{threshold} is subtracted from the score given in the algorithm description. If we designate the \emph{threshold} with $\epsilon$, the returned score is $r = \max(0, score - \epsilon)$, and the similarity condition from the algorithm description is transformed to $\text{cell\_similarity}(\mat{A},\mat{B},\epsilon) = 0$.
 \item For the vector length comparison, the row vectors of $\mat{A}$ and $\mat{B}$ are first sorted according to their length before comparing. This makes the similarity score independent on the vector order as long as the handedness of the matrices is the same.
\end{enumerate}

\subsubsection{Candidate Selection}

For selecting the best candidate the \emph{convenience} API provides a function that returns the index of the best candidate cell score.
%
\begin{lstlisting}
template <typename VecX>
unsigned best_cell (const DenseBase<VecX>& scores);
\end{lstlisting}

Given the candidate cell \textbf{scores} vector, the function simply returns the index to the most promising candidate cell $i = \argmin_j \vect{scores}_j$.

The \emph{convenience} API provides a function for selecting multiple candidate cells that are supposedly representing multiple crystals. This functions returns a vector of indices for the selected cells.
%
\begin{lstlisting}
template <typename CellMat,
          typename SpotMat,
          typename VecX,
          typename float_type=typename CellMat::Scalar>
vector<unsigned> select_crystals (
    const MatrixBase<CellMat>& cells,
    const MatrixBase<SpotMat>& spots,
    const DenseBase<VecX>& scores,
    float_type threshold=.00075,
    unsigned min_spots=8u,
    bool reciprocal=true
);
\end{lstlisting}

The \textbf{cells} $\in \mathbb{R}^{3m\times 3}$ and \textbf{spots} $\in \mathbb{R}^{n\times 3}$ matrices represent the $m$ candidate cells in real space and the $n$ spots in reciprocal space, respectively.

The \textbf{scores} $\in \mathbb{R}^m$ vector contains the scores for the candidate cells.

The \textbf{threshold} represents the $\beta$ parameter in the algorithm description for the cell selection.

The \textbf{min\_spots} argument represents the minimum number of fresh spots, denoted by $m$ in the algorithm description, a new candidate cell has to cover in order to be considered as a representative of a new crystal.

The \textbf{reciprocal} flag selects the distance measurement method. Distance to integer coordinates for \emph{false}, and distance between induced and measured spot for \emph{true}.

If two unit cell candidates have exactly the same score, the unit cell candidate obtained with the \emph{best\_cell} function might not be part of the unit cell candidate set obtained with \emph{select\_crystals}.

Before calling these functions, it is possible to influence the result by adding a positive penalty term to the scores, for example based on results from the \emph{cell\_similarity} function.

\subsubsection{Unit Cell Viability}

The \emph{convenience} API provides a function to check unit cell viability explicitly. A unit cell passes the check, if either at least \emph{min\_spots} have spot coordinates that approximate integer coordinates within \emph{threshold}, or the distance between induced and measured spots is within \emph{threshold} in reciprocal space for at least that many spots. If refinement has been done with the same \emph{min\_spots} parameter, and cell scores have not been fiddled with, this check can, for a unit cell candidate with index $i$, simply be replaced by a more performant $scores[i] < threshold$ check. However, if cell scores have been altered, or scores from the \emph{raw} API are used, this check is necessary.
%
\begin{lstlisting}
template <typename Mat3, typename MatX3,
          typename float_type=typename Mat3::Scalar>
inline bool is_viable_cell (
    const Eigen::MatrixBase<Mat3>& cell,
    const Eigen::MatrixBase<MatX3>& spots,
    float_type threshold=.00075,
    unsigned min_spots=8u,
    bool reciprocal=true
);
\end{lstlisting}

The \textbf{cell} matrix gives the single unit cell which should be checked for viability. The unit cell has to be in real space and its vectors must be present as row vectors.

The \textbf{spots} matrix gives the spots in reciprocal space as row vectors.

The \textbf{threshold} gives the distance limit, and the \textbf{min\_spots} argument the minimum acceptable number of spots that have to be approximated within the \emph{threshold}.

The \textbf{reciprocal} flag selects the distance measurement method. Distance to integer coordinates for \emph{false}, and distance between induced and measured spot for \emph{true}.

\subsection{Convenience Wrappers}

The \emph{convenience} API provides convenience wrappers for the \emph{raw} API indexer object, with space for input and output data as well as parameters. Convenient accessor functions are provided to write and read data.

\subsubsection{Raw Indexer Wrapper}

The \emph{convenience} API \emph{indexer} object is a wrapper for the \emph{raw} API indexer object and delivers the same results as the indexer object would. It keeps all the input and output data for indexing, as well as configuration data with parameters. The necessary data will be pinned on construction of the object. Spot and cell vectors are all stored in the rows of dense Eigen matrices, stored in column major order.
%
\begin{lstlisting}
template<typename float_type=float>
struct indexer {
    indexer (const config_persistent<float_type>& cp,
             const config_runtime<float_type>& cr);
    indexer (indexer&&) = default;
    indexer& operator= (indexer&&) = default;
    indexer () = delete;
    indexer (const indexer&) = delete;
    indexer& operator= (const indexer&) = delete;
    virtual ~indexer () = default;
    ...
}
\end{lstlisting}
%
Due to the extensive state in main and GPU memory, copying this \emph{indexer} object is expensive, that is why only move operations are allowed. Copying has to be explicit by constructing a new object with the same parameters. The input spots and cells are left uninitalized on construction and it is the users responsibility to fill in this data with functions described below, and also set the number of input cells and spots in a consistent way.
%
\begin{lstlisting}
...
void index_start (unsigned n_input_cells,
                  unsigned n_spots,
                  void(*callback)(void*)=nullptr,
                  void* data=nullptr);
virtual void index_end ();
void index (unsigned n_input_cells,
            unsigned n_spots);
...
\end{lstlisting}
%
Indexing operations are similar to the indexing functions in the \emph{raw} API, with the exception that the input, output, and runtime configuration parameters are replaced with \textbf{n\_input\_cells} and \textbf{n\_spots} parameters. The first three of those are part of the \emph{indexer} object, the latter two must match the number of input cells and spots, respectively. They correspond to the \emph{in.n\_cells} and \emph{in.n\_spots} parameters of the \emph{raw} API. A value of zero for \emph{n\_input\_cells} means that there are no new input cells, corresponding to \emph{in.new\_cells=false} in the \emph{raw} API. Likewise for a zero value of \emph{n\_spots} and \emph{in.new\_spots=false}.
%
\begin{lstlisting}
...
float_type& spotX (unsigned i=0u);
const float_type& spotX (unsigned i=0u) const;
float_type& spotY (unsigned i=0u);
const float_type& spotY (unsigned i=0u) const;
float_type& spotZ (unsigned i=0u);
const float_type& spotZ (unsigned i=0u) const;
auto& spotM ();
auto Spots ();
unsigned n_spots ()
...
\end{lstlisting}
%
Spot X coordinates can be retrieved and set with the \textbf{spotX}$(i)$ functions, where $i$ denotes the zero based spot index. Likewise for Y and Z coordinates and the \textbf{spotY}$(i)$ and \textbf{spotZ}$(i)$ functions, respectively. The \textbf{spotM} function returns a reference object to the entirety of the writeable Eigen matrix for the spots. It is the users responsibility to make sure underlying memory is not moved and that the limits of this matrix, given through the \emph{cp.max\_spots} parameter while constructing the \emph{indexer} object, are not violated. The \textbf{Spots} function returns an Eigen reference object to the last used top rows of the Eigen matrix for the spots and the \textbf{n\_spots} function returns the last used number of rows.
%
\begin{lstlisting}
...
float_type& iCellX (unsigned i=0u, unsigned j=0u);
const float_type& iCellX (unsigned i=0u,
                            unsigned j=0u) const;
float_type& iCellY (unsigned i=0u, unsigned j=0u);
const float_type& iCellY (unsigned i=0u,
                            unsigned j=0u) const;
float_type& iCellZ (unsigned i=0u, unsigned j=0u);
const float_type& iCellZ (unsigned i=0u,
                            unsigned j=0u) const;
auto iCell (unsigned i=0u);
auto iCell (unsigned i=0u) const;
auto& iCellM ();
unsigned n_input_cells ();
...
\end{lstlisting}
%
Input cell vector X coordinates can be retrieved and set with the \textbf{iCellX}$(i,j)$ functions, where $i$ is the zero based input cell index, and $0\leq j<3$ the zero based input cell vector index. Likewise for Y and Z coordinates and the \textbf{iCellY}$(i,j)$ and \textbf{iCellZ}$(i,j)$ functions, respectively. The \textbf{iCell}$(i)$ functions return reference objects to a block of the Eigen matrix holding the cell vectors for the input cell with zero based index $i$. The \textbf{iCellM} function returns a reference object to the entirety of the writeable Eigen matrix for input cells. It is the users responsibility to make sure underlying memory is not moved and that the limits of this matrix, given through the \emph{cp.max\_input\_cells} parameter while contructing the \emph{indexer} object, are not violated. The \textbf{n\_input\_cells} function returns the last used number of input cells.
%
\begin{lstlisting}
...
float_type& oCellX (unsigned i=0u, unsigned j=0u);
const float_type& oCellX (unsigned i=0u,
                            unsigned j=0u) const;
float_type& oCellY (unsigned i=0u, unsigned j=0u);
const float_type& oCellY (unsigned i=0u,
                            unsigned j=0u) const;
float_type& oCellZ (unsigned i=0u, unsigned j=0u);
const float_type& oCellZ (unsigned i=0u,
                            unsigned j=0u) const;
auto oCell (unsigned i);
auto oCell (unsigned i) const;
auto& oCellM ();
unsigned n_output_cells ();
...
\end{lstlisting}
%
Unit cell candidates are produced as output of the indexing functions. Output cell vector X coordinates can be retrieved and set with the \textbf{oCellX}$(i,j)$ functions, where $i$ is the zero based output cell index, and $0\leq j<3$ the zero based output cell vector index. Likewise for Y and Z coordinates and the \textbf{oCellY}$(i,j)$ and \textbf{oCellZ}$(i,j)$ functions, respectively. The \textbf{oCell}$(i)$ functions return reference objects to a block of the Eigen matrix holding the cell vectors for the output cell with zero based index $i$. The \textbf{oCellM} function returns a reference object to the entirety of the writeable Eigen matrix for output cells. It is the users responsibility to make sure underlying memory is not moved and that the limits of this matrix, given through the \emph{cp.max\_output\_cells} parameter while contructing the \emph{indexer} object, are not violated. The \textbf{n\_output\_cells} function returns the number of output cells.
%
\begin{lstlisting}
...
float_type& oScore (unsigned i=0u);
const float_type& oScore (unsigned i=0u) const;
auto& oScoreV ();
...
\end{lstlisting}
%
Unit cell candidate scores are produced as output of the indexing functions for every output cell. The output cell score can be retrieved and modified with the \textbf{oScore}$(i)$ functions, where $i$ is the zero based output cell index. The \textbf{oScoreV} function returns a reference object to the entirety of the writeable Eigen vector for output cell scores. It is the users responsibility to make sure underlying memory is not moved and that the limits of this vector, given through the \emph{cp.max\_output\_cells} parameter while contructing the \emph{indexer} object, are not violated.
%
\begin{lstlisting}
...
void length_threshold (float_type lt);
float_type length_threshold () const;
void triml (float_type tl);
float_type triml () const;
void trimh (float_type th);
float_type trimh () const;
void delta (float_type d);
float_type delta () const;
void dist1 (float_type d);
float_type dist1 () const;
void dist3 (float_type d);
float_type dist3 () const;
void num_halfsphere_points (unsigned nhsp);
unsigned num_halfsphere_points () const;
void num_angle_points (unsigned nap);
unsigned num_angle_points () const;
const config_runtime<float_type>&
    conf_runtime () const;
...
\end{lstlisting}
%
The \textbf{length\_threshold}, \textbf{triml}, \textbf{trimh}, \textbf{delta}, \textbf{dist1}, \textbf{dist3}, \textbf{num\_half\-sphe\-re\_points}, and \textbf{num\_angle\_points} functions provide access to the corresponding members of the \emph{runtime configuration} object. The \textbf{config\_runtime} function retrieves an immutable reference to this object. Initial values are given when constructing the \emph{indexer} object. Changing these values will have an effect on the next indexing operation.
%
\begin{lstlisting}
    ...
    unsigned max_output_cells () const;
    unsigned max_input_cells () const;
    unsigned max_spots () const;
    unsigned num_candidate_vectors () const;
    bool redundant_computations () const;
    const config_persistent<float_type>&
        conf_persistent () const;
}
\end{lstlisting}
%
The functions \textbf{max\_output\_cells}, \textbf{max\_input\_cells}, \textbf{max\_spots}, \textbf{num\_can\-di\-da\-te\_vec\-tors}, and \textbf{redundant\_computations} provide read only access to the corresponding members of the \emph{persistent configuration} object. The function \textbf{conf\_persistent} retrieves an immutable reference to this object. The values are given when constructing the \emph{indexer} object and influence the memory allocations in main and GPU memory for the \emph{indexer} object. Due to the associated cost, changing these values is not possible - instead discard the old and create a new \emph{indexer} object.

\subsection{Cell Refining Indexer}

To combine indexing on GPU and the final refinement in one go, the \emph{convenience} API provides the \textbf{indexer\_ifss} object. It applies the \emph{refine} function described earlier to the output cells after indexing. The refinement method, iterative fit to selected spots (\emph{ifss}) is described in the algorithm description, and the refinement configuration \emph{config\_ifss} was described earlier.
%
\begin{lstlisting}
template <typename float_type=float>
struct indexer_ifss : public indexer<float_type> {
    indexer_ifss (
        const config_persistent<float_type>& cp,
        const config_runtime<float_type>& cr,
        const config_ifss<float_type>& c
    );
    indexer_ifss (indexer_ifss&&) = default;
    indexer_ifss& operator= (indexer_ifss&&) = default;
    ~indexer_ifss () override = default;

    indexer_ifss () = delete;
    indexer_ifss (const indexer_ifss&) = delete;
    indexer_ifss& operator= (
        const indexer_ifss&
    ) = delete;

    template<typename MatX3, typename VecX>
    static void refine (
        const Ref<MatrixX3<float_type>>& spots,
        DenseBase<MatX3>& cells,
        DenseBase<VecX>& scores,
        const config_ifss<float_type>& cifss,
        unsigned block=0, unsigned nblocks=1
    );

    void index_end () override;
    ...
\end{lstlisting}
%
Apart from a specialized \textbf{index\_end} method calling the \textbf{refine} method after obtaining results from the \emph{indexer} object, this object needs an extra refinement configuration in the constructor. Otherwise it behaves the same as the \emph{indexer} object from which it inherits all members and methods publicly. Only for accessing configuration parameters it features extra functionality.
%
\begin{lstlisting}
    ...
    void threshold_contraction (float_type tc)
    float_type threshold_contraction () const
    void min_spots (unsigned ms)
    unsigned min_spots () const
    void max_distance (float_type d)
    float_type max_distance () const
    void max_iter (unsigned n)
    unsigned max_iter () const
    const config_ifss<float_type>& conf_ifss () const
}
\end{lstlisting}
%
The accessor methods \textbf{threshold\_contraction}, \textbf{min\_spots}, \textbf{max\_distance}, and \textbf{max\_iter} are for retrieving and setting the corresponding parameters in the refinement configuration. An immutable reference to the refinement configuration object can be obtained with the \textbf{conf\_ifss} method.

\subsection{Miscellaneous}

The \emph{indexer} object in the \emph{convenience} API provides a function to split apart the scores obtained from the \emph{raw} API.
%
\begin{lstlisting}
static std::pair<float_type, float_type>
score_parts (float_type score);
\end{lstlisting}
%
The \textbf{score\_parts} function returns a tuple $(n,d)$ with the number of close points $n$ and the average distance to integer coordinates for all spots $d$.

In addition to the \emph{indexer\_ifss} object that uses the refinement method described in the algorithm description, the \emph{convenience} API provides an experimental \textbf{indexer\_ifse} object that uses an iterative fit to selected errors method for refinement. This method is not described in the algorithm description, but it is very similar to the \emph{ifss} method in the algorithm description. Instead of fitting the cell candidate $\mat{B}$ to the spots $\mat{S}$ directly, it fits a delta $\mat{\Delta}$ to the residuals $\mat{R} = \mat{S}\mat{B}^T - \round{\mat{S}\mat{B}^T}$ in order to minimize $\mat{F}(\mat{S}\mat{\Delta}^T - \mat{R})$ through a least squares fit. The candidate cell is then updated with $\mat{B}:=\mat{B}+\mat{\Delta}$ for the next iteration.
%
\begin{lstlisting}
template<typename float_type=float> struct config_ifse;
template<typename float_type=float> struct indexer_ifse;
\end{lstlisting}
%
The refinement configuration is the same as for the \emph{ifss} method, and all methods and members are similar. The idea behind this experimental refinement is to bring the method closer to something resembling the steepest descent method and allow algorithm developers to try modifications of the $\mat{\Delta}$ delta matrix and its calculation.

To achieve a better fit between induced and measured spots, the \emph{convenience} API offers the experimental \textbf{indexer\_ifssr} object that uses an iterative fit to selected spots refinement method with another spot selection method. Instead of measuring the distance to induced integer spot coordinates, it measures the distance between given spot and induced spot in reciprocal space:
%
\[
d_i = \| \round{\vect{s}_i\mat{B}^T}\mat{B}^{-T} - \vect{s}_i \|.
\]
%
The spot is considered \emph{close}, if $d_i < t$, where $t$ is the current closeness threshold. The configuration and methods are the same as for the \emph{ifss} method.

\subsection{Thread Safety}

The \emph{convenience} API is not thread safe, with the exception of the unit cell candidate refinement that can be called by several threads at the same time on mutually exclusive blocks of unit candidate cells. Threads should either keep their own \emph{indexer} object or synchronize access to all members and methods. For the exception of the \emph{refine} method, threads need to make sure they call this method for mutually exclusive unit cell candidate blocks. However, read only operations can of course be executed in parallel. Read only data and methods are marked as \emph{const} throughout the \emph{convenience} API.

\section{Hard-coded Parameters}

In the algorithm description, some parameters are used that are currently hard-coded in the implementation.

The parameter called $m$ in the candidate vector orientation refinement is hard-coded to 6.

The parameter called $\tau$ in the mirror axis construction is hard-coded to the machine epsilon of the used floating point type.

\section{Python API}
\lstset{language=Python}

Through a module called \textbf{ffbidx}, the Python API provides very simple functions for experimentation with the fast feedback indexing software.

\subsection{The \emph{ffbidx} Module}

\begin{lstlisting}
# Import module
import ffbidx

# Create indexer object
indexer = ffbidx.Indexer(
    max_output_cells=32,
    max_input_cells=1,
    max_spots=300,
    num_candidate_vectors=32,
    redundant_computations=True
)

# Run indexing
output_cells, scores = indexer.run(
    spots,
    input_cells,
    method='ifssr',
    length_threshold=1e-9,
    triml=.001,
    trimh=.3,
    delta=0.1,
    dist1=.1,
    dist3=.15,
    num_sample_points=32*1024,
    n_output_cells=32,
    contraction=.8,
    max_dist=.00075,
    min_spots=8,
    n_iter=32
)

# Select crystals from cell candidates
indices = indexer.crystals(
  cells,
  spots,
  scores,
  method='ifssr',
  threshold=.00075,
  min_spots=8
)

# Dispose off the indexer object
indxer.__del__()
\end{lstlisting}
%
The \textbf{ffbidx.Indexer} function creates an indexer object. The arguments are
%
\begin{enumerate}
 \item \textbf{max\_output\_cells} - the maximum number of output cells generated
 \item \textbf{max\_input\_cells} - the maximum number of input cells considered
 \item \textbf{max\_spots} - the maximum number of spots considered
 \item \textbf{num\_candidate\_vectors} - the number of candidates kept between sampling stages
 \item \textbf{redundant\_calculations} - makes the code compute candidates for all vectors of an input cell instead of just one
\end{enumerate}
%
This allocates space on the GPU for all the data structures used in the computation.

The \textbf{indexer.run} method runs the fast feedback indexer and returns \emph{output\_cells} and their \emph{scores}. Output cell vectors are stored as consecutive column vectors with a \emph{C\_CONTIGUOUS} memory layout. The arguments are
%
\begin{enumerate}
 \item \textbf{spots} - a numpy array of reciprocal space spot coordinate vectors stored as column vectors in \emph{C\_CONTIGUOUS} memory layout, or row vectors in \emph{F\_CONTIGUOUS} memory layout.
 \item \textbf{input\_cells} - a numpy array of real space input cell vectors in consecutive groups of 3 vectors, stored as column vectors in \emph{C\_CONTIGUOUS} memory layout, or row vectors in \emph{F\_CONTIGUOUS} memory layout.
 \item \textbf{method} - refinement method: \emph{raw} (no refinement), \emph{ifss} (iterative fit to selected spots), \emph{ifse} (iterative fit to selected errors), \emph{ifssr} (iterative fit to selected spots reciprocal)
 \item \textbf{length\_threshold} - consider input cell vector length the same if they differ by less than this
 \item \textbf{triml} - low trim value, 0 means no trimming
 \item \textbf{trimh} - high trim value, 0.5 means no trimming
 \item \textbf{delta} - $\log_2$ curve position, lower values will increase selectiveness for close spots
 \item \textbf{dist1} - spots within this distance in coordinate space are contributing to the score in the vector sampling step. Will be set to \emph{trimh} if zero.
 \item \textbf{dist3} - spots within this distance in coordinate space are contributing to the score in the cell sampling step. Will be set to \emph{trimh} if zero.
 \item \textbf{num\_halfsphere\_points} - the number of sampling points on the half sphere for vector sampling
 \item \textbf{num\_angle\_points} - the number of angular sampling points for cell sampling
 \item \textbf{n\_output\_cells} - the number of desired output cells
 \item \textbf{contraction} - threshold contraction parameter for refinement methods
 \item \textbf{max\_dist} - maximum distance parameter for refinement methods, measured in coordinate space for methods \emph{ifss} and \emph{ifse}, and in reciprocal space for \emph{ifssr}
 \item \textbf{min\_spots} - minimum number of spots to fit against for refinement methods
 \item \textbf{n\_iter} - maximum number of iterations for refinement methods
\end{enumerate}

The \textbf{indexer.crystals} method calculates the indices of cells that represent separate crystals. The arguments are
%
\begin{enumerate}
 \item \textbf{cells} - a numpy array of real space candidate cell vectors in consecutive groups of 3 vectors, stored as column vectors in \emph{C\_CONTIGUOUS} memory layout, or row vectors in \emph{F\_CONTIGUOUS} memory layout.
 \item \textbf{spots} - a numpy array of reciprocal space spot coordinate vectors stored as column vectors in \emph{C\_CONTIGUOUS} memory layout, or row vectors in \emph{F\_CONTIGUOUS} memory layout.
 \item \textbf{scores} - a numpy array of candidate cell scores, one for each candidate cell, stored in contiguous memory.
 \item \textbf{method} - distance measurement method. Measures the distance between given and induced spot for method \emph{ifssr}, for \emph{raw}, \emph{ifss}, \emph{ifss} the distance to nearest integer coordinates is considered.
 \item \textbf{threshold} - distance threshold for considering a spot covered by the candidate cell.
 \item \textbf{min\_spots} - minimum number of extra spots covered by a candidate cell for considering the cell a representative of a separate crystal.
\end{enumerate}

The \textbf{indexer.\_\_del\_\_()} method disposes off an indexer objects state on the GPU and on the CPU.

\subsection{Issues}

The unit cell selection functionality is missing, but with \emph{np.argmin(scores)} the same functionality is achieved as for \emph{best\_cell()}, where \emph{np} stands for the \emph{numpy} python module. And the functionality of \emph{is\_viable\_cell(B,S,t,m)} is expressed as \emph{np.sum(np.linalg.norm(S@B.T - np.rint(S@B.T), axis=1) $<$ t) $>=$ m}, when $S$ and $B$ contain the vectors as rows.

\section{Simple Use Cases}

This section describes very simple use cases.

\subsection{\emph{Raw} API}
\lstset{language=C++}

The \emph{raw} API, in combination with the basic functionality of the \emph{convenience} API, offers the biggest flexibility and speed potential. Since the \emph{convenience} API works with row vectors in Eigen matrices \cite{eigenweb} stored in column major memory order, data should be kept in this form, or at least in a form easily convertable to such matrices. The rationale for column major row vector matrices is the avoidance of memory access strides detrimental to performance.

The following code first creates a toy setup by hardcoding some Miller indices in $\mat{Coords}$ and a lattice base $\mat{B}$ as a rotated version of $\mat{B0}$. The spots in reciprocal space spots are then $\mat{Spots}=\mat{Coords}\cdot\mat{B}^{-1}$. The indexer should now find $\mat{B}$ when given the $\mat{Spots}$ and $\mat{B0}$.
%
\begin{lstlisting}
#include <Eigen/LU>
#include <iostream>
#include <cmath>
#include <atomic>
#include <thread>
#include <chrono>
#include <ffbidx/refine.h>

using std::cout;
using std::flush;
using std::atomic_bool;
using Mx3 = Eigen::MatrixX3f;
using M3 = Eigen::Matrix3f;
using Vx = Eigen::VectorXf;
using Eigen::Map;
using LU = Eigen::FullPivLU<M3>;
using namespace std::chrono_literals;
using namespace fast_feedback;
using ifss = refine::indexer_ifss<>;
using refine::best_cell;
using refine::is_viable_cell;
constexpr float PI = 3.14159265358979323846;
constexpr float _60 = PI/3.0f;

void callback(void *data) {
  cout << '!' << flush;
  ((atomic_bool*)data)->store(true);
};

int main(int argc, char* argv[]) {
  float coords[3][10] = {
    {1.0, 4.0, 1.0, 2.0, 6.0, 4.0, 7.0, 8.0, 5.0, 9.0},
    {2.0, 5.0, 1.0, 1.0, 3.0, 5.0, 1.0, 2.0, 7.0, 8.0},
    {3.0, 6.0, 7.0, 4.0, 1.0, 2.0, 3.0, 6.0, 5.0, 8.0}
  };
  float base[3][3] = {
    {2.0, 0.0, 0.0},
    {0.0, 1.0, 0.0},
    {0.0, 0.0, 1.0}
  };
  float rot60z[3][3] = {
    {  cosf(_60), sinf(_60), 0 },
    { -sinf(_60), cosf(_60), 0 },
    {          0,         0, 1 }
  };
  Mx3 Coords = Map<Mx3>((float*)coords, 10, 3);
  M3 B0 = Map<M3>((float*)base, 3, 3);
  M3 R60z = Map<M3>((float*)rot60z, 3, 3);
  M3 B = B0 * R60z.transpose();
  LU lu(B);
  M3 Binv = lu.inverse();
  Mx3 Spots = Coords * Binv.transpose();
  Mx3 Cand(3*32, 3);
  Vx Score(32);

  cout << "True Coords:\n" << Coords
       << "\nB0:\n" << B0
       << "\nR60z:\n" << R60z
       << "\nB:\n" << B
       << "\nBinv:\n" << Binv
       << "\nSpots:\n" << Spots << '\n';

  input<> in{
    {&B0(0,0), &B0(0,1), &B0(0,2)},
    {&Spots(0,0), &Spots(0,1), &Spots(0,2)},
    1, 10, true, true
  };
  output<> out{
    &Cand(0,0), &Cand(0,1), &Cand(0,2),
    &Score(0), 32
  };
  config_persistent<> cp{
    32, 1, 10, 32, true
  };
  config_runtime<> cr{};
  refine::config_ifss<> ci{};

  memory_pin pin_b0{B0};
  memory_pin pin_spots{Spots};
  memory_pin pin_cand{Cand};
  memory_pin pin_score{Score};
  memory_pin pin_cr = memory_pin::on(cr);

  indexer<> indexer(cp);

  atomic_bool finished{false};
  indexer.index_start(
    in, out, cr,
    callback, (void*)&finished
  );
  while (! finished.load()) {
    cout << '.';
    std::this_thread::sleep_for(100us);
  }
  cout << '\n';
  indexer.index_end(out);
  ifss::refine(Spots, Cand, Score, ci, 0, 2);
  ifss::refine(Spots, Cand, Score, ci, 1, 2);
  unsigned best = best_cell(Score);

  cout << "Cand:\n" << Cand
       << "\nScore:\n" << Score
       << "\nBest: " << best << '\n';

  float sf = Score(best);
  M3 Bf = Cand.block(3*best, 0, 3, 3);
  bool viable = (sf < .001f);

  cout << "B found:\n" << Bf
       << "\nScore: " << sf
       << ", Viable: " << (viable?"yes":"no")
       << "\nComputed Coords:\n"
       << (Spots * Bf.transpose()) << '\n';
}
\end{lstlisting}
%
Notice how the program sets up space for 32 candidate unit cells and their score. Also note how these Eigen matrices and vectors are pinned. Since they are C++ containers, they can be used as the argument for the \emph{memory\_pin} contructors directly. The coordinate $\vect{x},\vect{y},\vect{z}$ vectors can easily be extracted from Eigen matrices, since they have a column major memory layout. Note how the runtime configuration \emph{cr} is pinned.

The code launches the indexing on the GPU asynchronously, giving the \emph{callback} function an argument to the boolean \emph{finished}. This allows to execiute other code while the first part of the indexing operation is running on the GPU. For synchronous operation, the \emph{index\_start} and \emph{index\_end} pair can be replaced with the simpler \emph{index} variant.

For illustration purposes, the final refinement step on CPU is split into two blocks. These are handled consecutively here - real code should handle them concurrently.

Because scores have not been tampered with, the viability check can be done by comparing the score directly to a threshold. The minimal number of spots is taken from the \emph{ifss} refinement configuration, the default of which is stored as a member of \emph{ci} here. Otherwise, for example if \emph{cell\_similarity} was used as a penalty term to enhance the score, the \emph{is\_viable\_cell} function would have to be called to achieve the same.

\subsection{\emph{Convenience} API}

The \emph{convenience} API indexer wrappers provide space for storing data and also handle pinning. It is still the programmers responsibility to make sure underlying memory of the data is not moved. The following provides the same as before, with the exception that refinement is done in one block. Splitting refinement up into several blocks is not possible with the convenience indexer wrappers.
%
\begin{lstlisting}
#include <Eigen/LU>
#include <iostream>
#include <cmath>
#include <atomic>
#include <thread>
#include <chrono>
#include <ffbidx/refine.h>

using std::cout;
using std::flush;
using std::atomic_bool;
using Mx3 = Eigen::MatrixX3f;
using M3 = Eigen::Matrix3f;
using Vx = Eigen::VectorXf;
using Eigen::Map;
using LU = Eigen::FullPivLU<M3>;
using namespace std::chrono_literals;
using namespace fast_feedback;
using ifss = refine::indexer_ifss<>;
using refine::best_cell;
constexpr float PI = 3.14159265358979323846;
constexpr float _60 = PI/3.0f;

void callback(void *data) {
    cout << '!' << flush;
    ((atomic_bool*)data)->store(true);
};

int main(int argc, char* argv[]) {
  float coords[3][10] = {
    {1.0, 4.0, 1.0, 2.0, 6.0, 4.0, 7.0, 8.0, 5.0, 9.0},
    {2.0, 5.0, 1.0, 1.0, 3.0, 5.0, 1.0, 2.0, 7.0, 8.0},
    {3.0, 6.0, 7.0, 4.0, 1.0, 2.0, 3.0, 6.0, 5.0, 8.0}
  };
  float base[3][3] = {
    {2.0, 0.0, 0.0},
    {0.0, 1.0, 0.0},
    {0.0, 0.0, 1.0}
  };
  float rot60z[3][3] = {
    {  cosf(_60), sinf(_60), 0 },
    { -sinf(_60), cosf(_60), 0 },
    {          0,         0, 1 }
  };
  Mx3 Coords = Map<Mx3>((float*)coords, 10, 3);
  M3 B0 = Map<M3>((float*)base, 3, 3);
  M3 R60z = Map<M3>((float*)rot60z, 3, 3);
  M3 B = B0 * R60z.transpose();
  LU lu(B);
  M3 Binv = lu.inverse();
  Mx3 Spots = Coords * Binv.transpose();

  cout << "True Coords:\n" << Coords
       << "\nB0:\n" << B0
       << "\nR60z:\n" << R60z
       << "\nB:\n" << B
       << "\nBinv:\n" << Binv
       << "\nSpots:\n" << Spots << '\n';

  config_persistent<> cp{
    32, 1, 10, 32, true
  };
  config_runtime<> cr{};
  refine::config_ifss<> ci{};

  ifss indexer(cp, cr, ci);
  indexer.spotM() = Spots;
  indexer.iCellM() = B0;

  atomic_bool finished{false};
  indexer.index_start(1, 10, callback, &finished);
  while (! finished.load()) {
    cout << '.';
    std::this_thread::sleep_for(100us);
  }
  cout << '\n';
  indexer.index_end();
  unsigned best = best_cell(indexer.oScoreV());

  cout << "Cand:\n" << indexer.oCellM()
       << "\nScore:\n" << indexer.oScoreV()
       << "\nBest: " << best << '\n';

  float sf = indexer.oScore(best);
  M3 Bf = indexer.oCell(best);
  bool viable = (sf < .001f);

  cout << "B found:\n" << Bf
       << "\nScore: " << sf
       << ", Viable: " << (viable?"yes":"no")
       << "\nComputed Coords:\n"
       << (Spots * Bf.transpose()) << '\n';
}
\end{lstlisting}
%
Note the absence of explicit memory pinning. The consequence is that data needs to copied to pinned memory. Here, since we know the capacities set up by the persistent configuration \emph{cp} fit exactly, the internal spot matrix is assigned to directly, using the \emph{spotM} function to get its reference. In a more realistic scenario, spots would have to be assigned one by one using the \emph{spotX}, \emph{spotY}, and \emph{spotZ} methods, or the Eigen \emph{block} or \emph{row} methods on the internal spot matrix. A similar issue exists with the input cell, where we could have used the \emph{iCell} method instead for getting a reference in order to assign the single input cell. Or we could have used the \emph{iCellX}, \emph{iCellY}, and \emph{iCellZ} methods to assign input cell vector elements one by one.

\subsection{Python API}
\lstset{language=Python}

The Python API aimed at experimenting with the algorithm. The equivalent of the above two calculations is listed below.
%
\begin{lstlisting}
import numpy as np
import ffbidx

_60 = np.pi/3.0

Coords = np.reshape(
  np.array(
    [1.0, 4.0, 1.0, 2.0, 6.0, 4.0, 7.0, 8.0, 5.0, 9.0,
     2.0, 5.0, 1.0, 1.0, 3.0, 5.0, 1.0, 2.0, 7.0, 8.0,
     3.0, 6.0, 7.0, 4.0, 1.0, 2.0, 3.0, 6.0, 5.0, 8.0],
    dtype='float32'
  ),
  (10,3), order='F'
)

B0 = np.reshape(
  np.array(
    [2.0, 0.0, 0.0,
     0.0, 1.0, 0.0,
     0.0, 0.0, 1.0],
    dtype='float32'
  ),
  (3,3), order='F'
)

R60z = np.reshape(
  np.array(
    [np.cos(_60), np.sin(_60), 0,
     -np.sin(_60), np.cos(_60), 0,
     0, 0, 1],
    dtype='float32'
  ),
  (3,3), order='F'
)

B = np.matmul(B0, R60z.T, order='F')
Binv = np.asfortranarray(np.linalg.inv(B))
Spots = np.matmul(Coords, Binv.T, order='F')

print("True Coords:\n", Coords)
print("B0:\n", B0)
print("R60z:\n", R60z)
print("B:\n", B)
print("Binv:\n", Binv)
print("Spots:\n", Spots)

handle = ffbidx.indexer(32, 1, 10, 32, True)
Cand, Score = ffbidx.index(handle, Spots, B0,
                           method='ifss',
                           n_output_cells=32)
ffbidx.release(handle)
best = np.argmin(Score)
Cand = np.reshape(Cand.ravel(), (3*32,3), order='F')

print("Cand\n", Cand)
print("Score\n", Score)
print("Best:", best)

sf = Score[best]
Bf = Cand[3*best:3*best+3, 0:3]
viable = (sf < .001)

print("B found:\n", Bf)
print(f"Score: {sf}, Viable: {viable}")
print("Computed Coords:\n", Spots@Bf.T)
\end{lstlisting}
%
Unfortunately, the column major memory ordering is a bit awkward to keep up. Instead of \emph{F\_CONTIGUOUS} arrays, it would also be possible to work with \emph{C\_CONTIGUOUS} arrays in their transposed versions. The Python API currently lacks the means to achieve the best performance.

\printbibliography
\end{document}
